nohup: ignoring input
Seed set to 0
/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
You are using a CUDA device ('NVIDIA A10') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/spacy/language.py:2141: FutureWarning: Possible set union at position 6328
  deserializers["tokenizer"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/utilities/model_summary/model_summary.py:452: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.

  | Name | Type      | Params
-----------------------------------
0 | lm   | BertModel | 109 M 
1 | ner  | NER       | 1.6 K 
-----------------------------------
109 M     Trainable params
0         Non-trainable params
109 M     Total params
439.508   Total estimated model params size (MB)
/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=29` in the `DataLoader` to improve performance.
using recursive instantiate
using recursive instantiate
using recursive instantiate
using recursive instantiate
using recursive instantiate
using recursive instantiate
using recursive instantiate
using recursive instantiate
using recursive instantiate
using recursive instantiate
configuring optimizers
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/400 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/400 [00:00<?, ?it/s] /home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:385: You have overridden `transfer_batch_to_device` in `LightningModule` but have passed in a `LightningDataModule`. It will use the implementation from `LightningModule` instance.
Epoch 0:   0%|          | 1/400 [00:00<03:41,  1.80it/s]Epoch 0:   0%|          | 1/400 [00:00<03:41,  1.80it/s, v_num=285]Epoch 0:   0%|          | 2/400 [00:00<01:58,  3.36it/s, v_num=285]Epoch 0:   0%|          | 2/400 [00:00<01:58,  3.36it/s, v_num=285]Epoch 0:   1%|          | 3/400 [00:00<01:26,  4.60it/s, v_num=285]Epoch 0:   1%|          | 3/400 [00:00<01:26,  4.60it/s, v_num=285]Epoch 0:   1%|          | 4/400 [00:00<01:10,  5.64it/s, v_num=285]Epoch 0:   1%|          | 4/400 [00:00<01:10,  5.63it/s, v_num=285]Epoch 0:   1%|▏         | 5/400 [00:00<01:00,  6.53it/s, v_num=285]Epoch 0:   1%|▏         | 5/400 [00:00<01:00,  6.53it/s, v_num=285]Epoch 0:   2%|▏         | 6/400 [00:00<00:55,  7.07it/s, v_num=285]Epoch 0:   2%|▏         | 6/400 [00:00<00:55,  7.07it/s, v_num=285]Epoch 0:   2%|▏         | 7/400 [00:00<00:51,  7.65it/s, v_num=285]Epoch 0:   2%|▏         | 7/400 [00:00<00:51,  7.65it/s, v_num=285]Epoch 0:   2%|▏         | 8/400 [00:00<00:47,  8.29it/s, v_num=285]Epoch 0:   2%|▏         | 8/400 [00:00<00:47,  8.28it/s, v_num=285]Epoch 0:   2%|▏         | 9/400 [00:01<00:45,  8.66it/s, v_num=285]Epoch 0:   2%|▏         | 9/400 [00:01<00:45,  8.66it/s, v_num=285]Epoch 0:   2%|▎         | 10/400 [00:01<00:43,  9.03it/s, v_num=285]Epoch 0:   2%|▎         | 10/400 [00:01<00:43,  9.03it/s, v_num=285]Epoch 0:   3%|▎         | 11/400 [00:01<00:41,  9.40it/s, v_num=285]Epoch 0:   3%|▎         | 11/400 [00:01<00:41,  9.40it/s, v_num=285]Epoch 0:   3%|▎         | 12/400 [00:01<00:39,  9.80it/s, v_num=285]Epoch 0:   3%|▎         | 12/400 [00:01<00:39,  9.80it/s, v_num=285]Epoch 0:   3%|▎         | 13/400 [00:01<00:37, 10.21it/s, v_num=285]Epoch 0:   3%|▎         | 13/400 [00:01<00:37, 10.21it/s, v_num=285]Epoch 0:   4%|▎         | 14/400 [00:01<00:37, 10.41it/s, v_num=285]Epoch 0:   4%|▎         | 14/400 [00:01<00:37, 10.41it/s, v_num=285]Epoch 0:   4%|▍         | 15/400 [00:01<00:36, 10.68it/s, v_num=285]Epoch 0:   4%|▍         | 15/400 [00:01<00:36, 10.67it/s, v_num=285]Epoch 0:   4%|▍         | 16/400 [00:01<00:34, 10.97it/s, v_num=285]Epoch 0:   4%|▍         | 16/400 [00:01<00:34, 10.97it/s, v_num=285]Epoch 0:   4%|▍         | 17/400 [00:01<00:34, 11.13it/s, v_num=285]Epoch 0:   4%|▍         | 17/400 [00:01<00:34, 11.12it/s, v_num=285]Epoch 0:   4%|▍         | 18/400 [00:01<00:33, 11.32it/s, v_num=285]Epoch 0:   4%|▍         | 18/400 [00:01<00:33, 11.32it/s, v_num=285]Epoch 0:   5%|▍         | 19/400 [00:01<00:33, 11.46it/s, v_num=285]Epoch 0:   5%|▍         | 19/400 [00:01<00:33, 11.46it/s, v_num=285]Epoch 0:   5%|▌         | 20/400 [00:01<00:33, 11.48it/s, v_num=285]Epoch 0:   5%|▌         | 20/400 [00:01<00:33, 11.48it/s, v_num=285]Epoch 0:   5%|▌         | 21/400 [00:01<00:32, 11.54it/s, v_num=285]Epoch 0:   5%|▌         | 21/400 [00:01<00:32, 11.54it/s, v_num=285]Epoch 0:   6%|▌         | 22/400 [00:01<00:32, 11.69it/s, v_num=285]Epoch 0:   6%|▌         | 22/400 [00:01<00:32, 11.69it/s, v_num=285]Epoch 0:   6%|▌         | 23/400 [00:01<00:31, 11.80it/s, v_num=285]Epoch 0:   6%|▌         | 23/400 [00:01<00:31, 11.80it/s, v_num=285]Epoch 0:   6%|▌         | 24/400 [00:02<00:31, 11.91it/s, v_num=285]Epoch 0:   6%|▌         | 24/400 [00:02<00:31, 11.91it/s, v_num=285]Epoch 0:   6%|▋         | 25/400 [00:02<00:31, 11.87it/s, v_num=285]Epoch 0:   6%|▋         | 25/400 [00:02<00:31, 11.87it/s, v_num=285]Epoch 0:   6%|▋         | 26/400 [00:02<00:31, 11.95it/s, v_num=285]Epoch 0:   6%|▋         | 26/400 [00:02<00:31, 11.95it/s, v_num=285]Epoch 0:   7%|▋         | 27/400 [00:02<00:30, 12.05it/s, v_num=285]Epoch 0:   7%|▋         | 27/400 [00:02<00:30, 12.05it/s, v_num=285]Epoch 0:   7%|▋         | 28/400 [00:02<00:30, 12.13it/s, v_num=285]Epoch 0:   7%|▋         | 28/400 [00:02<00:30, 12.13it/s, v_num=285]Epoch 0:   7%|▋         | 29/400 [00:02<00:30, 12.23it/s, v_num=285]Epoch 0:   7%|▋         | 29/400 [00:02<00:30, 12.23it/s, v_num=285]Epoch 0:   8%|▊         | 30/400 [00:02<00:29, 12.34it/s, v_num=285]Epoch 0:   8%|▊         | 30/400 [00:02<00:29, 12.34it/s, v_num=285]Epoch 0:   8%|▊         | 31/400 [00:02<00:29, 12.46it/s, v_num=285]Epoch 0:   8%|▊         | 31/400 [00:02<00:29, 12.46it/s, v_num=285]Epoch 0:   8%|▊         | 32/400 [00:02<00:29, 12.53it/s, v_num=285]Epoch 0:   8%|▊         | 32/400 [00:02<00:29, 12.53it/s, v_num=285]Epoch 0:   8%|▊         | 33/400 [00:02<00:29, 12.50it/s, v_num=285]Epoch 0:   8%|▊         | 33/400 [00:02<00:29, 12.50it/s, v_num=285]Epoch 0:   8%|▊         | 34/400 [00:02<00:29, 12.56it/s, v_num=285]Epoch 0:   8%|▊         | 34/400 [00:02<00:29, 12.56it/s, v_num=285]Epoch 0:   9%|▉         | 35/400 [00:02<00:28, 12.65it/s, v_num=285]Epoch 0:   9%|▉         | 35/400 [00:02<00:28, 12.65it/s, v_num=285]Epoch 0:   9%|▉         | 36/400 [00:02<00:28, 12.75it/s, v_num=285]Epoch 0:   9%|▉         | 36/400 [00:02<00:28, 12.75it/s, v_num=285]Epoch 0:   9%|▉         | 37/400 [00:02<00:28, 12.80it/s, v_num=285]Epoch 0:   9%|▉         | 37/400 [00:02<00:28, 12.80it/s, v_num=285]Epoch 0:  10%|▉         | 38/400 [00:02<00:28, 12.82it/s, v_num=285]Epoch 0:  10%|▉         | 38/400 [00:02<00:28, 12.82it/s, v_num=285]Epoch 0:  10%|▉         | 39/400 [00:03<00:28, 12.80it/s, v_num=285]Epoch 0:  10%|▉         | 39/400 [00:03<00:28, 12.80it/s, v_num=285]Epoch 0:  10%|█         | 40/400 [00:03<00:27, 12.86it/s, v_num=285]Epoch 0:  10%|█         | 40/400 [00:03<00:27, 12.86it/s, v_num=285]Epoch 0:  10%|█         | 41/400 [00:03<00:27, 12.87it/s, v_num=285]Epoch 0:  10%|█         | 41/400 [00:03<00:27, 12.87it/s, v_num=285]Epoch 0:  10%|█         | 42/400 [00:03<00:27, 12.96it/s, v_num=285]Epoch 0:  10%|█         | 42/400 [00:03<00:27, 12.95it/s, v_num=285]Epoch 0:  11%|█         | 43/400 [00:03<00:27, 13.02it/s, v_num=285]Epoch 0:  11%|█         | 43/400 [00:03<00:27, 13.02it/s, v_num=285]Epoch 0:  11%|█         | 44/400 [00:03<00:27, 13.06it/s, v_num=285]Epoch 0:  11%|█         | 44/400 [00:03<00:27, 13.06it/s, v_num=285]Epoch 0:  11%|█▏        | 45/400 [00:03<00:27, 13.10it/s, v_num=285]Epoch 0:  11%|█▏        | 45/400 [00:03<00:27, 13.10it/s, v_num=285]Epoch 0:  12%|█▏        | 46/400 [00:03<00:27, 13.08it/s, v_num=285]Epoch 0:  12%|█▏        | 46/400 [00:03<00:27, 13.08it/s, v_num=285]Epoch 0:  12%|█▏        | 47/400 [00:03<00:26, 13.14it/s, v_num=285]Epoch 0:  12%|█▏        | 47/400 [00:03<00:26, 13.14it/s, v_num=285]Epoch 0:  12%|█▏        | 48/400 [00:03<00:26, 13.20it/s, v_num=285]Epoch 0:  12%|█▏        | 48/400 [00:03<00:26, 13.20it/s, v_num=285]Epoch 0:  12%|█▏        | 49/400 [00:03<00:26, 13.09it/s, v_num=285]Epoch 0:  12%|█▏        | 49/400 [00:03<00:26, 13.09it/s, v_num=285]Epoch 0:  12%|█▎        | 50/400 [00:03<00:26, 13.06it/s, v_num=285]Epoch 0:  12%|█▎        | 50/400 [00:03<00:26, 13.06it/s, v_num=285]Epoch 0:  13%|█▎        | 51/400 [00:03<00:26, 13.03it/s, v_num=285]Epoch 0:  13%|█▎        | 51/400 [00:03<00:26, 13.03it/s, v_num=285]Epoch 0:  13%|█▎        | 52/400 [00:03<00:26, 13.04it/s, v_num=285]Epoch 0:  13%|█▎        | 52/400 [00:03<00:26, 13.04it/s, v_num=285]Epoch 0:  13%|█▎        | 53/400 [00:04<00:26, 13.06it/s, v_num=285]Epoch 0:  13%|█▎        | 53/400 [00:04<00:26, 13.06it/s, v_num=285]Epoch 0:  14%|█▎        | 54/400 [00:04<00:26, 13.10it/s, v_num=285]Epoch 0:  14%|█▎        | 54/400 [00:04<00:26, 13.10it/s, v_num=285]Epoch 0:  14%|█▍        | 55/400 [00:04<00:26, 13.14it/s, v_num=285]Epoch 0:  14%|█▍        | 55/400 [00:04<00:26, 13.14it/s, v_num=285]Epoch 0:  14%|█▍        | 56/400 [00:04<00:26, 13.17it/s, v_num=285]Epoch 0:  14%|█▍        | 56/400 [00:04<00:26, 13.17it/s, v_num=285]Epoch 0:  14%|█▍        | 57/400 [00:04<00:25, 13.22it/s, v_num=285]Epoch 0:  14%|█▍        | 57/400 [00:04<00:25, 13.22it/s, v_num=285]Epoch 0:  14%|█▍        | 58/400 [00:04<00:25, 13.24it/s, v_num=285]Epoch 0:  14%|█▍        | 58/400 [00:04<00:25, 13.24it/s, v_num=285]Epoch 0:  15%|█▍        | 59/400 [00:04<00:25, 13.26it/s, v_num=285]Epoch 0:  15%|█▍        | 59/400 [00:04<00:25, 13.25it/s, v_num=285]Epoch 0:  15%|█▌        | 60/400 [00:04<00:25, 13.26it/s, v_num=285]Epoch 0:  15%|█▌        | 60/400 [00:04<00:25, 13.26it/s, v_num=285]Epoch 0:  15%|█▌        | 61/400 [00:04<00:25, 13.34it/s, v_num=285]Epoch 0:  15%|█▌        | 61/400 [00:04<00:25, 13.34it/s, v_num=285]Epoch 0:  16%|█▌        | 62/400 [00:04<00:25, 13.43it/s, v_num=285]Epoch 0:  16%|█▌        | 62/400 [00:04<00:25, 13.43it/s, v_num=285]Epoch 0:  16%|█▌        | 63/400 [00:04<00:24, 13.49it/s, v_num=285]Epoch 0:  16%|█▌        | 63/400 [00:04<00:24, 13.49it/s, v_num=285]Epoch 0:  16%|█▌        | 64/400 [00:04<00:24, 13.54it/s, v_num=285]Epoch 0:  16%|█▌        | 64/400 [00:04<00:24, 13.54it/s, v_num=285]Epoch 0:  16%|█▋        | 65/400 [00:04<00:24, 13.62it/s, v_num=285]Epoch 0:  16%|█▋        | 65/400 [00:04<00:24, 13.62it/s, v_num=285]Epoch 0:  16%|█▋        | 66/400 [00:04<00:24, 13.69it/s, v_num=285]Epoch 0:  16%|█▋        | 66/400 [00:04<00:24, 13.69it/s, v_num=285]Epoch 0:  17%|█▋        | 67/400 [00:04<00:24, 13.74it/s, v_num=285]Epoch 0:  17%|█▋        | 67/400 [00:04<00:24, 13.73it/s, v_num=285]Epoch 0:  17%|█▋        | 68/400 [00:04<00:24, 13.76it/s, v_num=285]Epoch 0:  17%|█▋        | 68/400 [00:04<00:24, 13.76it/s, v_num=285]Epoch 0:  17%|█▋        | 69/400 [00:04<00:23, 13.82it/s, v_num=285]Epoch 0:  17%|█▋        | 69/400 [00:04<00:23, 13.82it/s, v_num=285]Epoch 0:  18%|█▊        | 70/400 [00:05<00:23, 13.84it/s, v_num=285]Epoch 0:  18%|█▊        | 70/400 [00:05<00:23, 13.84it/s, v_num=285]Epoch 0:  18%|█▊        | 71/400 [00:05<00:23, 13.84it/s, v_num=285]Epoch 0:  18%|█▊        | 71/400 [00:05<00:23, 13.84it/s, v_num=285]Epoch 0:  18%|█▊        | 72/400 [00:05<00:23, 13.86it/s, v_num=285]Epoch 0:  18%|█▊        | 72/400 [00:05<00:23, 13.86it/s, v_num=285]Epoch 0:  18%|█▊        | 73/400 [00:05<00:23, 13.85it/s, v_num=285]Epoch 0:  18%|█▊        | 73/400 [00:05<00:23, 13.85it/s, v_num=285]Epoch 0:  18%|█▊        | 74/400 [00:05<00:23, 13.82it/s, v_num=285]Epoch 0:  18%|█▊        | 74/400 [00:05<00:23, 13.82it/s, v_num=285]Epoch 0:  19%|█▉        | 75/400 [00:05<00:23, 13.83it/s, v_num=285]Epoch 0:  19%|█▉        | 75/400 [00:05<00:23, 13.83it/s, v_num=285]Epoch 0:  19%|█▉        | 76/400 [00:05<00:23, 13.88it/s, v_num=285]Epoch 0:  19%|█▉        | 76/400 [00:05<00:23, 13.88it/s, v_num=285]Epoch 0:  19%|█▉        | 77/400 [00:05<00:23, 13.90it/s, v_num=285]Epoch 0:  19%|█▉        | 77/400 [00:05<00:23, 13.90it/s, v_num=285]Epoch 0:  20%|█▉        | 78/400 [00:05<00:23, 13.91it/s, v_num=285]Epoch 0:  20%|█▉        | 78/400 [00:05<00:23, 13.91it/s, v_num=285]Epoch 0:  20%|█▉        | 79/400 [00:05<00:23, 13.90it/s, v_num=285]Epoch 0:  20%|█▉        | 79/400 [00:05<00:23, 13.90it/s, v_num=285]Epoch 0:  20%|██        | 80/400 [00:05<00:23, 13.89it/s, v_num=285]Epoch 0:  20%|██        | 80/400 [00:05<00:23, 13.89it/s, v_num=285]Epoch 0:  20%|██        | 81/400 [00:05<00:22, 13.89it/s, v_num=285]Epoch 0:  20%|██        | 81/400 [00:05<00:22, 13.89it/s, v_num=285]Epoch 0:  20%|██        | 82/400 [00:05<00:22, 13.86it/s, v_num=285]Epoch 0:  20%|██        | 82/400 [00:05<00:22, 13.86it/s, v_num=285]Epoch 0:  21%|██        | 83/400 [00:05<00:22, 13.87it/s, v_num=285]Epoch 0:  21%|██        | 83/400 [00:05<00:22, 13.87it/s, v_num=285]Epoch 0:  21%|██        | 84/400 [00:06<00:22, 13.87it/s, v_num=285]Epoch 0:  21%|██        | 84/400 [00:06<00:22, 13.87it/s, v_num=285]Epoch 0:  21%|██▏       | 85/400 [00:06<00:22, 13.92it/s, v_num=285]Epoch 0:  21%|██▏       | 85/400 [00:06<00:22, 13.92it/s, v_num=285]Epoch 0:  22%|██▏       | 86/400 [00:06<00:22, 13.92it/s, v_num=285]Epoch 0:  22%|██▏       | 86/400 [00:06<00:22, 13.91it/s, v_num=285]Epoch 0:  22%|██▏       | 87/400 [00:06<00:22, 13.94it/s, v_num=285]Epoch 0:  22%|██▏       | 87/400 [00:06<00:22, 13.94it/s, v_num=285]Epoch 0:  22%|██▏       | 88/400 [00:06<00:22, 13.92it/s, v_num=285]Epoch 0:  22%|██▏       | 88/400 [00:06<00:22, 13.92it/s, v_num=285]Epoch 0:  22%|██▏       | 89/400 [00:06<00:22, 13.91it/s, v_num=285]Epoch 0:  22%|██▏       | 89/400 [00:06<00:22, 13.91it/s, v_num=285]Epoch 0:  22%|██▎       | 90/400 [00:06<00:22, 13.88it/s, v_num=285]Epoch 0:  22%|██▎       | 90/400 [00:06<00:22, 13.88it/s, v_num=285]Epoch 0:  23%|██▎       | 91/400 [00:06<00:22, 13.89it/s, v_num=285]Epoch 0:  23%|██▎       | 91/400 [00:06<00:22, 13.88it/s, v_num=285]Epoch 0:  23%|██▎       | 92/400 [00:06<00:22, 13.91it/s, v_num=285]Epoch 0:  23%|██▎       | 92/400 [00:06<00:22, 13.91it/s, v_num=285]Epoch 0:  23%|██▎       | 93/400 [00:06<00:22, 13.92it/s, v_num=285]Epoch 0:  23%|██▎       | 93/400 [00:06<00:22, 13.92it/s, v_num=285]Epoch 0:  24%|██▎       | 94/400 [00:06<00:21, 13.94it/s, v_num=285]Epoch 0:  24%|██▎       | 94/400 [00:06<00:21, 13.94it/s, v_num=285]Epoch 0:  24%|██▍       | 95/400 [00:06<00:21, 13.99it/s, v_num=285]Epoch 0:  24%|██▍       | 95/400 [00:06<00:21, 13.99it/s, v_num=285]Epoch 0:  24%|██▍       | 96/400 [00:06<00:21, 14.02it/s, v_num=285]Epoch 0:  24%|██▍       | 96/400 [00:06<00:21, 14.02it/s, v_num=285]Epoch 0:  24%|██▍       | 97/400 [00:06<00:21, 13.96it/s, v_num=285]Epoch 0:  24%|██▍       | 97/400 [00:06<00:21, 13.96it/s, v_num=285]Epoch 0:  24%|██▍       | 98/400 [00:07<00:21, 13.97it/s, v_num=285]Epoch 0:  24%|██▍       | 98/400 [00:07<00:21, 13.97it/s, v_num=285]Epoch 0:  25%|██▍       | 99/400 [00:07<00:21, 13.99it/s, v_num=285]Epoch 0:  25%|██▍       | 99/400 [00:07<00:21, 13.99it/s, v_num=285]Epoch 0:  25%|██▌       | 100/400 [00:07<00:21, 13.99it/s, v_num=285]Epoch 0:  25%|██▌       | 100/400 [00:07<00:21, 13.99it/s, v_num=285]Epoch 0:  25%|██▌       | 101/400 [00:07<00:21, 14.02it/s, v_num=285]Epoch 0:  25%|██▌       | 101/400 [00:07<00:21, 14.02it/s, v_num=285]Epoch 0:  26%|██▌       | 102/400 [00:07<00:21, 14.03it/s, v_num=285]Epoch 0:  26%|██▌       | 102/400 [00:07<00:21, 14.03it/s, v_num=285]Epoch 0:  26%|██▌       | 103/400 [00:07<00:21, 14.05it/s, v_num=285]Epoch 0:  26%|██▌       | 103/400 [00:07<00:21, 14.05it/s, v_num=285]Epoch 0:  26%|██▌       | 104/400 [00:07<00:21, 14.05it/s, v_num=285]Epoch 0:  26%|██▌       | 104/400 [00:07<00:21, 14.05it/s, v_num=285]Epoch 0:  26%|██▋       | 105/400 [00:07<00:20, 14.06it/s, v_num=285]Epoch 0:  26%|██▋       | 105/400 [00:07<00:20, 14.06it/s, v_num=285]Epoch 0:  26%|██▋       | 106/400 [00:07<00:20, 14.06it/s, v_num=285]Epoch 0:  26%|██▋       | 106/400 [00:07<00:20, 14.06it/s, v_num=285]Epoch 0:  27%|██▋       | 107/400 [00:07<00:20, 14.06it/s, v_num=285]Epoch 0:  27%|██▋       | 107/400 [00:07<00:20, 14.06it/s, v_num=285]Epoch 0:  27%|██▋       | 108/400 [00:07<00:20, 14.04it/s, v_num=285]Epoch 0:  27%|██▋       | 108/400 [00:07<00:20, 14.04it/s, v_num=285]Epoch 0:  27%|██▋       | 109/400 [00:07<00:20, 14.08it/s, v_num=285]Epoch 0:  27%|██▋       | 109/400 [00:07<00:20, 14.08it/s, v_num=285]Epoch 0:  28%|██▊       | 110/400 [00:07<00:20, 14.08it/s, v_num=285]Epoch 0:  28%|██▊       | 110/400 [00:07<00:20, 14.08it/s, v_num=285]Epoch 0:  28%|██▊       | 111/400 [00:07<00:20, 14.11it/s, v_num=285]Epoch 0:  28%|██▊       | 111/400 [00:07<00:20, 14.11it/s, v_num=285]Traceback (most recent call last):
  File "/home/ubuntu/DocRE/spacy_main.py", line 90, in <module>
    cli = LightningCLI(ELRELightningModule, ELREDataModule)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/cli.py", line 386, in __init__
    self._run_subcommand(self.subcommand)
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/cli.py", line 677, in _run_subcommand
    fn(**fn_kwargs)
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 989, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 1035, in _run_stage
    self.fit_loop.run()
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py", line 359, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 136, in run
    self.advance(data_fetcher)
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 240, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 187, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 265, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/core/module.py", line 1291, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py", line 151, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py", line 230, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py", line 117, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/torch/optim/adamw.py", line 161, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py", line 104, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 140, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 126, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 315, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py", line 309, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py", line 382, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/DocRE/spacy_lightning_module.py", line 408, in training_step
    ner_loss = self.ner_training_step(example, token_embeddings)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/DocRE/spacy_lightning_module.py", line 295, in ner_training_step
    logits = self.ner(candidate_spans, token_embeddings)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/DocRE/spacy_modeling_classes.py", line 119, in forward
    span_embeddings = self.span_embedder(spans, token_embeddings, length_embeddings)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/ELRE/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/DocRE/spacy_modeling_classes.py", line 69, in forward
    pooled_embeddings.append(self._pooled_token_embedding(el, token_embeddings))
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/DocRE/spacy_modeling_classes.py", line 53, in _pooled_token_embedding
    return pooled_embedding
           ^^^^^^^^^^^^^^^^
UnboundLocalError: cannot access local variable 'pooled_embedding' where it is not associated with a value
Epoch 0:  28%|██▊       | 111/400 [00:09<00:24, 12.00it/s, v_num=285]